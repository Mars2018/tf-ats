## DATA PARAMS ##
item_id             = 55381 # 
rand_seed           = 251967169

chkpt_dir           = chkpt/mod
#data_dir            = /home/david/data/ats/ets
data_dir            = /home/david/data/ets1b/2016
vocab_file          = vocab_n250.txt

min_word_count      = 5
valid_cut           = 0.2

## MODEL PARAMS ##
rnn_unit            = lstm # lstm gru rwa rhn
rnn_dim             = 100
rnn_layers          = 1
# max_text_length     = 1000

trim_words
# bidirectional
# train_initial_state
# peepholes
# skip_connections

## RNN AGGREGATION ##
mean_pool
att_size            = 50

# num_highway_layers  = 1

## TRAINING PARAMS ##
batch_size          = 32
optimizer           = adam # adam rmsprop
learning_rate       = 0.001
epochs              = 30
max_grad_norm       = 5.0
dropout             = 0.5
print_every         = 10
# learning_rate_decay = 0.75

kernel_widths       = '[1,2,3,4,5,6,7]'
char_embed_size     = 15
kernel_features     = '[25,50,75,100,100,100,100]'
char_embed_chkpt    = /home/david/code/python/tf-lstm-char-cnn/chkpt/mod2_600-15

# char_embed_size     = 20
# kernel_features     = '[50,100,150,200,200,200,200]'
# char_embed_chkpt    = /home/david/code/python/tf-lstm-char-cnn/chkpt/mod1_650-20

embed_path          = /home/david/data/embed/glove.6B.{}d.txt
embed_dim           = 100

embed_type          = char